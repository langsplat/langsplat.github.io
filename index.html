<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="3D Language Gaussian Splatting">
  <meta name="keywords" content="LangSplat, 3D Gaussian Splatting, LERF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LangSplat: 3D Language Gaussian Splatting</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://github.com/minghanqin">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://minghanqin.github.io/AvatarSVE/">
            AvatarSVE
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">LangSplat: Deformable Neural Radiance Fields</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/minghanqin">Minghan Qin</a><sup>1*</sup>,</span>
            <span class="author-block">
              Wanhua Li<sup>2*&#134;</sup>,</span>
            <span class="author-block">
              Jiawei Zhou<sup>1*</sup>,
            </span>
            <span class="author-block">
              Haoqian Wang<sup>1&#134;</sup>,
            </span>
            <span class="author-block">
              Hanspeter Pfister<sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tsinghua University,</span>
            <span class="author-block"><sup>2</sup>Harvard University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.png"/>
      <h2 class="subtitle has-text-centered">
        Visualization of learned features of the previous SOTA method LERF and 
        our LangSplat. LangSplat grounds CLIP features into a set of 3D Language 
        Gaussians to construct a 3D language field. While LERF generates imprecise 
        and vague 3D features, our LangSplat accurately captures object boundaries 
        and provides precise 3D language fields without any post-processing. While 
        being effective, our LangSplat is also 199 &times; faster than LERF at the 
        resolution of 1440 &times; 1080.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Human lives in a 3D world and commonly uses natural language to interact with a 3D scene. Modeling a 3D
language field to support open-ended language queries in
3D has gained increasing attention recently. This paper introduces LangSplat, which constructs a 3D language field
that enables precise and efficient open-vocabulary query-
ing within 3D spaces. Unlike existing methods that ground
CLIP language embeddings in a NeRF model, LangSplat
advances the field by utilizing a collection of 3D Gaussians, each encoding language features distilled from CLIP,
to represent the language field. By employing a tile-based
splatting technique for rendering language features, we circumvent the costly rendering process inherent in NeRF.
Instead of directly learning CLIP embeddings, LangSplat
first trains a scene-wise language autoencoder and then
learns language features on the scene-specific latent space,
thereby alleviating substantial memory demands imposed
            by explicit modeling. Existing methods struggle with imprecise and vague 3D language fields, which fail to discern clear boundaries between objects. We delve into this
issue and propose to learn hierarchical semantics using
SAM, thereby eliminating the need for extensively querying
the language field across various scales and the regularization of DINO features. Extensive experiments on open-
vocabulary 3D object localization and semantic segmentation demonstrate that LangSplat significantly outperforms
the previous state-of-the-art method LERF by a large margin. Notably, LangSplat is extremely efficient, achieving a
199 × speedup compared to LERF at the resolution of 1440 × 1080. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->




<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <!-- Re-rendering. -->
        <h3 class="title is-4">Visualization of learned features of the LangSplat</h3>
        <div class="content has-text-justified">
          <p>
            A 3D language field is learned by grounding CLIP language features into a set of 3D language Gaussians.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/feature1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!--/ Re-rendering. -->
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/feature2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/feature3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/feature4.mp4"
                    type="video/mp4">
          </video>
        </div>
        
        <h3 class="title is-4">Open-vocabulary 3D Query of the LangSplat vs LERF</h3>
        <div class="content has-text-justified">
          <p>
            Our LangSplat is able to focus more precisely on the queried object.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/ovq1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/ovq2.mp4"
                    type="video/mp4">
          </video>
        </div>

        <h3 class="title is-4">Open-vocabulary 3D Semantic Segmentation results of the LangSplat</h3>
        <div class="content has-text-justified">
          <p>
            Our method is 199 &times; faster than LERF at 1440*1080 resolution.
            Prior to any text query, our language field already exhibits precise 3D object boundaries.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/semantic1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/semantic2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>



</body>
</html>
